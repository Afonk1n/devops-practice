## Laravel-проект: что уже сделано (технически и зачем это DevOps’у)

Этот файл фиксирует текущее состояние **практики 02 (Laravel)**. Структура разбита на блоки, соответствующие этапам работы.

---

## Блок 1: Docker + docker-compose + CI

**Что мы сделали в этом блоке:**
- Создали структуру Laravel-проекта
- Собрали Docker-образы для PHP-FPM и Nginx
- Настроили docker-compose для локального окружения
- Настроили CI на GitHub Actions

**Закрывает требования вакансии:**
- ✅ "Работать с инфраструктурой как код (IaC)"
- ✅ "Умение читать и отлаживать Dockerfile, работать с образами контейнеров"
- ✅ "Поддерживать и развивать CI/CD-процессы для Laravel-приложений"
- ✅ "Опыт работы с хотя бы одним CI/CD-инструментом (GitHub Actions)"
- ✅ "Знание принципов работы веб-приложений: HTTP, Nginx, PHP-FPM"

---

### Раздел 1.1: Структура проекта

**Что мы сделали:**

Мы создали структуру проекта `laravel-app/`, которая содержит всё необходимое для запуска Laravel-приложения в Docker и Kubernetes.

**Структура папок:**

- **`laravel-app/src/`** — сам Laravel-проект:
  - создан через `composer create-project laravel/laravel src` (это стандартная команда для создания нового Laravel-проекта);
  - зависимости установлены через `composer install` (скачиваются все PHP-библиотеки, которые нужны Laravel);
  - сгенерирован `APP_KEY` через `php artisan key:generate` (это ключ шифрования, который Laravel использует для защиты данных);
  - миграции выполнены через `php artisan migrate` (создаются таблицы в базе данных).

- **`laravel-app/docker/`** — Docker-образы:
  - `php-fpm/Dockerfile` — образ для PHP-FPM (где выполняется Laravel-код);
  - `nginx/Dockerfile` + `nginx/nginx.conf` — образ и конфигурация для Nginx (веб-сервер).

- **`laravel-app/docker-compose.yml`** — описание локального окружения:
  - `app` (PHP-FPM + Laravel-код),
  - `nginx` (веб-сервер),
  - `db` (MySQL база данных),
  - `redis` (для кеша и очередей).

- **`.github/workflows/laravel-ci.yml`** — автоматический пайплайн CI/CD (GitHub Actions).

**Почему это важно для DevOps:**

> **Закрывает требования вакансии:**
> - ✅ **"Работать с инфраструктурой как код (IaC)"** — вся структура проекта описана в файлах (Dockerfile, docker-compose.yml, k8s-манифесты);
> - ✅ **"Умение читать и отлаживать Dockerfile"** — мы создали и настроили Dockerfile'ы для PHP-FPM и Nginx;
> - ✅ **"Желание разбираться в Laravel-экосистеме"** — мы понимаем структуру Laravel-проекта и как он работает.

Ты умеешь не просто «запустить Laravel», а **структурировать проект так, чтобы его можно было автоматически собирать, стартовать и проверять** на любой машине: разработчика, CI-раннера, сервера. Это основа для дальнейшей работы с Kubernetes и CI/CD.

**Вопрос:** *зачем нужен PHP-FPM, что это такое вообще, что такое Nginx, как это описывать словами, какие функции они выполняют?*  
**Ответ (по-простому):**
- **PHP-FPM** — это менеджер процессов PHP, пул воркеров, который постоянно висит в памяти и выполняет PHP‑код по запросу веб‑сервера. В нашей схеме Nginx отправляет запросы в PHP-FPM, тот запускает Laravel‑код, ходит в базу/Redis и отдаёт ответ обратно.
- **Nginx** — фронтовый веб‑сервер и обратный прокси. Он принимает HTTP‑запросы от браузеров, сам раздаёт статику (CSS/JS/картинки), а динамические запросы прокидывает дальше — в PHP‑FPM или другие сервисы. Плюс на уровне Nginx обычно настраивают HTTPS, балансировку, редиректы.
- Вместе это описывается так: *«Nginx слушает порт 80/443, отдаёт статику и проксирует PHP‑запросы в PHP‑FPM. PHP‑FPM — пул PHP‑воркеров, который исполняет Laravel‑код и возвращает результат Nginx’у, а тот — пользователю.»*

---

### Раздел 1.2: Docker для Laravel (php-fpm + Nginx)

**Что мы сделали:**

Мы создали Docker-образы для PHP-FPM и Nginx, чтобы упаковать Laravel-приложение в контейнеры. Это позволяет запускать приложение на любой машине, где есть Docker, без необходимости устанавливать PHP, Nginx и все зависимости вручную.

**Почему это важно:**

> **Закрывает требования вакансии:**
> - ✅ **"Умение читать и отлаживать Dockerfile, работать с образами контейнеров"** — мы создали и настроили Dockerfile'ы;
> - ✅ **"Знание принципов работы веб-приложений: HTTP, Nginx, PHP-FPM/Octane"** — мы понимаем, как Nginx и PHP-FPM работают вместе.

**Простыми словами:**

Docker — это способ упаковать приложение со всеми его зависимостями в "коробку" (образ). Когда ты запускаешь эту "коробку" (контейнер), внутри уже есть всё необходимое: PHP, нужные расширения, настройки. Тебе не нужно думать "а установлен ли PHP на сервере?", "а какая версия?", "а есть ли нужные расширения?" — всё уже внутри образа.

---

#### 2.1. `docker/php-fpm/Dockerfile`

**Что это такое:**

Dockerfile — это **инструкция, как собрать образ**. Ты описываешь пошагово: "возьми базовый образ PHP, установи нужные расширения, скопируй код, запусти PHP-FPM".

**Разбор по строкам:**

```dockerfile
FROM php:8.3-fpm
```

**Что делает:**
- Берёт готовый образ `php:8.3-fpm` как основу (это официальный образ от PHP, в нём уже установлен PHP 8.3 в режиме FPM).

**Почему `8.3-fpm`:**
- `8.3` — версия PHP, которая поддерживается Laravel 12;
- `fpm` — это режим работы PHP (FastCGI Process Manager), который нужен для работы с Nginx.

**Простыми словами:**
- Без FPM: PHP запускается каждый раз заново при каждом запросе (медленно);
- С FPM: PHP запускается один раз и висит в памяти, обрабатывая запросы быстро.

```dockerfile
RUN apt-get update && apt-get install -y \
    git \
    unzip \
    libpq-dev \
    libzip-dev \
    zip \
    && docker-php-ext-install pdo pdo_mysql pdo_pgsql zip \
    && pecl install redis \
    && docker-php-ext-enable redis \
    && rm -rf /var/lib/apt/lists/*
```

**Что делает:**
- `apt-get update` — обновляет список доступных пакетов (как `sudo apt update` в Ubuntu);
- `apt-get install -y git unzip libpq-dev libzip-dev zip` — устанавливает системные библиотеки:
  - `git` — нужен для Composer (менеджер зависимостей PHP);
  - `unzip`, `zip`, `libzip-dev` — нужны для работы с архивами (Composer скачивает пакеты в виде zip);
  - `libpq-dev` — библиотеки для работы с PostgreSQL (на всякий случай, если понадобится).
- `docker-php-ext-install pdo pdo_mysql pdo_pgsql zip` — устанавливает PHP-расширения:
  - `pdo`, `pdo_mysql`, `pdo_pgsql` — для подключения к базам данных (MySQL, PostgreSQL);
  - `zip` — для работы с архивами в PHP.
- `pecl install redis` — устанавливает расширение Redis через PECL (это репозиторий PHP-расширений);
- `docker-php-ext-enable redis` — включает расширение Redis (чтобы PHP мог его использовать);
- `rm -rf /var/lib/apt/lists/*` — удаляет кеш пакетов (чтобы образ был меньше).

**Почему это нужно:**

Laravel использует:
- MySQL/PostgreSQL для хранения данных → нужны расширения `pdo_mysql`, `pdo_pgsql`;
- Redis для кеша и очередей → нужно расширение `redis`;
- Composer для установки зависимостей → нужны `git`, `unzip`, `zip`.

Без этих расширений Laravel не сможет подключиться к базе или использовать Redis.

```dockerfile
WORKDIR /var/www/html
```

**Что делает:**
- Устанавливает рабочую директорию (куда будут копироваться файлы, где будут выполняться команды).

**Почему `/var/www/html`:**
- Это стандартная папка для веб-приложений в Linux;
- В docker-compose мы монтируем код Laravel в эту папку: `./src:/var/www/html`.

```dockerfile
CMD ["php-fpm"]
```

**Что делает:**
- Запускает PHP-FPM при старте контейнера.

**Почему это важно:**

Когда контейнер запускается, он должен знать, какую команду выполнить. `CMD` говорит Docker: "запусти `php-fpm`", и PHP-FPM начинает слушать запросы от Nginx.

**Зачем DevOps'у понимать Dockerfile:**

> **Закрывает требования вакансии:**
> - ✅ **"Умение читать и отлаживать Dockerfile"** — ты понимаешь, что делает каждая строка;
> - ✅ **"Работать с образами контейнеров"** — ты умеешь собрать образ (`docker build`) и запустить контейнер (`docker run`).

Ты должен уметь:
- Понять, почему образ не собирается (например, не хватает библиотеки);
- Добавить новое расширение, если понадобится;
- Оптимизировать образ (сделать его меньше, быстрее собирать).

#### 2.2. `docker/nginx/Dockerfile` и `nginx.conf`

**Что это такое:**

Nginx — это **веб-сервер**, который принимает HTTP-запросы от браузеров и решает, что с ними делать: отдать статический файл (CSS, JS, картинки) или отправить дальше в PHP-FPM для обработки.

**Разбор Dockerfile:**

```dockerfile
FROM nginx:alpine
```

**Что делает:**
- Берёт готовый образ `nginx:alpine` (это официальный образ Nginx, собранный на Alpine Linux — очень маленький и быстрый).

**Почему `alpine`:**
- Образ получается очень маленьким (несколько мегабайт вместо сотен);
- Для Nginx этого достаточно, потому что он просто проксирует запросы.

```dockerfile
WORKDIR /etc/nginx

COPY nginx.conf /etc/nginx/conf.d/default.conf
```

**Что делает:**
- Копирует наш конфиг `nginx.conf` в папку, где Nginx ищет конфигурации (`/etc/nginx/conf.d/default.conf`).

**Почему это нужно:**

По умолчанию Nginx использует стандартный конфиг, который не подходит для Laravel. Нам нужен свой конфиг, который:
- Знает, где находится Laravel (`/var/www/html/public`);
- Проксирует PHP-запросы в PHP-FPM;
- Правильно обрабатывает статические файлы.

**Разбор `nginx.conf`:**

```nginx
server {
    listen 80;
    server_name localhost;

    root /var/www/html/public;
    index index.php index.html;
```

**Что делает:**
- `listen 80` — Nginx слушает порт 80 (стандартный HTTP-порт);
- `server_name localhost` — это виртуальный хост (можно указать домен, например `example.com`);
- `root /var/www/html/public` — корневая папка для файлов (в Laravel это папка `public`, где лежит `index.php`);
- `index index.php index.html` — если запросили папку без файла, искать `index.php` или `index.html`.

**Почему `/var/www/html/public`, а не просто `/var/www/html`:**

В Laravel структура такая:
- `/var/www/html/` — весь проект (код, конфиги, зависимости);
- `/var/www/html/public/` — **только то, что можно показывать в браузере** (`index.php`, CSS, JS, картинки).

Всё остальное (код приложения, `.env`, конфиги) находится выше и **не должно быть доступно из браузера** (это безопасность).

```nginx
location / {
    try_files $uri $uri/ /index.php?$query_string;
}
```

**Что делает:**
- `location /` — это правило для всех запросов, которые начинаются с `/`;
- `try_files $uri $uri/ /index.php?$query_string` — попробуй:
  1. Найти файл по запрошенному пути (`$uri`);
  2. Если не нашёл — попробуй найти папку (`$uri/`);
  3. Если и папки нет — отдай всё в `index.php` с параметрами запроса (`$query_string`).

**Почему это нужно:**

Laravel использует **роутинг** (маршрутизацию). Когда пользователь заходит на `/users/123`, Laravel не ищет файл `users/123.php`, а смотрит в свои маршруты и решает, какой контроллер вызвать. Поэтому все запросы должны идти в `index.php`, где Laravel-роутер их обработает.

```nginx
location ~ \.php$ {
    include fastcgi_params;
    fastcgi_pass app:9000;
    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
}
```

**Что делает:**
- `location ~ \.php$` — это правило для всех файлов, которые заканчиваются на `.php` (регулярное выражение);
- `include fastcgi_params` — подключает стандартные параметры для FastCGI (это протокол, по которому Nginx общается с PHP-FPM);
- `fastcgi_pass app:9000` — отправляет запрос в контейнер `app` на порт 9000 (там слушает PHP-FPM);
- `fastcgi_param SCRIPT_FILENAME ...` — говорит PHP-FPM, какой файл нужно выполнить.

**Почему `app:9000`:**

В docker-compose у нас есть сервис `app` (PHP-FPM), который слушает порт 9000. Docker-compose автоматически создаёт DNS-имена для сервисов, поэтому `app` резолвится в IP-адрес контейнера с PHP-FPM.

**Как это работает вместе:**

1. Браузер отправляет запрос: `GET /users/123 HTTP/1.1`
2. Nginx получает запрос на порту 80
3. Nginx смотрит правило `location /` → не находит файл `/users/123` → отправляет в `index.php?/users/123`
4. Nginx видит, что это `.php` файл → срабатывает `location ~ \.php$`
5. Nginx отправляет запрос в PHP-FPM через `fastcgi_pass app:9000`
6. PHP-FPM получает запрос, запускает Laravel-код
7. Laravel обрабатывает маршрут `/users/123`, возвращает HTML
8. PHP-FPM отправляет HTML обратно в Nginx
9. Nginx отправляет HTML в браузер

**Зачем DevOps'у понимать Nginx:**

> **Закрывает требования вакансии:**
> - ✅ **"Знание принципов работы веб-приложений: HTTP, Nginx, PHP-FPM"** — ты понимаешь, как Nginx и PHP-FPM работают вместе;
> - ✅ **"Взаимодействовать с командой бэкенд-разработчиков: помогать с оптимизацией окружения"** — ты можешь настроить Nginx для оптимальной работы Laravel.

Ты должен уметь:
- Настроить Nginx для Laravel (правильные пути, проксирование в PHP-FPM);
- Понять, почему запрос не доходит до Laravel (проблема в Nginx или в PHP-FPM?);
- Оптимизировать Nginx (кеширование, сжатие, правильная обработка статики).

**Вопрос:** *не могу это описать словами, как объяснять на собесе?*  
**Ответ:** можно использовать такую формулировку:  
*«Я поднимаю Laravel в связке Nginx + PHP‑FPM. Nginx принимает HTTP‑запросы, статику отдаёт сам, а всё остальное через `fastcgi_pass` отправляет в PHP‑FPM. PHP‑FPM — это пул PHP‑воркеров, который исполняет Laravel‑код, обращается к базе и Redis и отдаёт HTML/JSON‑ответ обратно в Nginx, а тот возвращает его клиенту.»*

---

### Раздел 1.3: docker-compose: локальное продоподобное окружение

**Что мы сделали:**

Мы создали файл `docker-compose.yml`, который описывает **всё окружение приложения**: веб-сервер, PHP-FPM, базу данных, Redis. Одна команда `docker compose up` запускает все эти сервисы вместе, и они автоматически настраиваются для работы друг с другом.

**Что такое docker-compose:**

**Простыми словами:**

Docker-compose — это способ **описать несколько контейнеров в одном файле** и запустить их все вместе. Вместо того чтобы запускать каждый контейнер отдельно командой `docker run`, ты описываешь все сервисы в YAML-файле, и docker-compose сам их запускает и настраивает сеть между ними.

**Аналогия:**
- `docker run` = ты вручную запускаешь каждый контейнер и настраиваешь связи;
- `docker compose` = у тебя есть "рецепт" (docker-compose.yml), и docker-compose сам всё готовит по этому рецепту.

**Почему это важно:**

> **Закрывает требования вакансии:**
> - ✅ **"Работать с инфраструктурой как код (IaC)"** — docker-compose.yml описывает всю инфраструктуру в коде;
> - ✅ **"Взаимодействовать с командой бэкенд-разработчиков: помогать с оптимизацией окружения"** — разработчики могут запустить то же окружение, что и в проде, одной командой.

**Разбор `docker-compose.yml`:**

**Сервис `app` (PHP-FPM):**

```yaml
app:
  build:
    context: .
    dockerfile: docker/php-fpm/Dockerfile
  volumes:
    - ./src:/var/www/html
  env_file:
    - ./src/.env
  depends_on:
    - db
    - redis
```

**Что делает:**
- `build: context: . dockerfile: docker/php-fpm/Dockerfile` — собирает образ из Dockerfile в папке `docker/php-fpm/`;
- `volumes: ./src:/var/www/html` — монтирует папку `./src` (код Laravel) в контейнер в `/var/www/html` (это значит, что изменения в коде сразу видны в контейнере, не нужно пересобирать образ);
- `env_file: ./src/.env` — загружает переменные окружения из файла `.env` Laravel;
- `depends_on: db, redis` — говорит docker-compose: "сначала запусти `db` и `redis`, потом уже `app`" (чтобы Laravel мог подключиться к базе и Redis).

**Почему `volumes`:**

Без `volumes` код Laravel был бы **зашит в образ** (пришлось бы пересобирать образ при каждом изменении кода). С `volumes` код монтируется **из папки на твоём компьютере**, поэтому изменения видны сразу (удобно для разработки).

**Сервис `nginx`:**

```yaml
nginx:
  build:
    context: .
    dockerfile: docker/nginx/Dockerfile
  ports:
    - "8082:80"
  volumes:
    - ./src:/var/www/html:ro
  depends_on:
    - app
```

**Что делает:**
- `build: ... docker/nginx/Dockerfile` — собирает образ Nginx;
- `ports: "8082:80"` — пробрасывает порт: когда ты заходишь на `localhost:8082` на твоём компьютере, запрос идёт на порт 80 внутри контейнера Nginx;
- `volumes: ./src:/var/www/html:ro` — монтирует код Laravel, но **только для чтения** (`:ro` = read-only), потому что Nginx не должен изменять код;
- `depends_on: app` — сначала запускается `app` (PHP-FPM), потом `nginx`.

**Почему `:ro` (read-only):**

Nginx только **читает** файлы (отдаёт их в браузер или проксирует в PHP-FPM). Ему не нужно писать в файлы, поэтому мы даём ему доступ только на чтение (это безопаснее).

**Сервис `db` (MySQL):**

```yaml
db:
  image: mysql:8.0
  environment:
    MYSQL_DATABASE: laravel
    MYSQL_USER: laravel
    MYSQL_PASSWORD: secret
    MYSQL_ROOT_PASSWORD: root
  ports:
    - "3307:3306"
  volumes:
    - db_data:/var/lib/mysql
```

**Что делает:**
- `image: mysql:8.0` — использует готовый образ MySQL версии 8.0 (не собираем сами, берём готовый);
- `environment:` — переменные окружения, которые MySQL использует при первом запуске:
  - `MYSQL_DATABASE: laravel` — создаёт базу данных с именем `laravel`;
  - `MYSQL_USER: laravel` — создаёт пользователя `laravel`;
  - `MYSQL_PASSWORD: secret` — пароль для пользователя `laravel`;
  - `MYSQL_ROOT_PASSWORD: root` — пароль для root-пользователя (администратор).
- `ports: "3307:3306"` — пробрасывает порт MySQL на твой компьютер (чтобы можно было подключиться извне, например, через MySQL Workbench);
- `volumes: db_data:/var/lib/mysql` — сохраняет данные базы в именованный volume (чтобы данные не пропали при перезапуске контейнера).

**Почему именованный volume `db_data`:**

Если просто монтировать папку (`./data:/var/lib/mysql`), то при удалении контейнера данные могут потеряться. Именованный volume (`db_data`) управляется Docker'ом, и данные сохраняются даже если контейнер пересоздаётся.

**Сервис `redis`:**

```yaml
redis:
  image: redis:alpine
  ports:
    - "6379:6379"
```

**Что делает:**
- `image: redis:alpine` — использует готовый образ Redis (Alpine-версия, маленькая);
- `ports: "6379:6379"` — пробрасывает стандартный порт Redis.

**Почему Redis нужен:**

> **Закрывает требования вакансии:**
> - ✅ **"Знание принципов работы веб-приложений: ... кэширование (Redis)"** — мы используем Redis для кеша;
> - ✅ **"Взаимодействовать с командой бэкенд-разработчиков: ... очередей (Redis)"** — Redis используется для очередей задач в Laravel.

Laravel использует Redis для:
- **Кеширования** — быстрый доступ к часто используемым данным (например, результаты запросов к базе);
- **Очередей** — фоновые задачи (отправка email, обработка изображений) выполняются асинхронно через очереди.

**Как всё это работает вместе:**

1. Ты запускаешь `docker compose up`
2. Docker-compose читает файл и понимает: "нужно запустить 4 сервиса: `app`, `nginx`, `db`, `redis`"
3. Docker-compose создаёт **виртуальную сеть** для всех контейнеров
4. В этой сети контейнеры могут обращаться друг к другу **по имени** (например, `app` может подключиться к `db:3306`)
5. Запускаются контейнеры в правильном порядке (сначала `db` и `redis`, потом `app`, потом `nginx`)
6. Ты открываешь браузер → `http://localhost:8082` → запрос идёт в Nginx → Nginx проксирует в PHP-FPM → Laravel обрабатывает → возвращает ответ

**Команда запуска:**

```bash
cd /mnt/d/DevOpsPractice/laravel-app
docker compose up --build
```

**Что делает `--build`:**
- Пересобирает образы перед запуском (на случай, если Dockerfile изменился).

**После запуска:**
- `http://localhost:8082` — стартовая страница Laravel;
- MySQL доступна на `localhost:3307` (можно подключиться извне);
- Redis доступен на `localhost:6379`;
- Все сервисы общаются внутри сети docker-compose по именам (`app`, `db`, `redis`).

**Почему это важно DevOps'у:**

- Ты умеешь **смоделировать прод-окружение локально**:
  - То, что потом будет в Kubernetes/облаке, ты уже видишь дома;
  - Разработчики могут повторить окружение одной командой (не нужно вручную устанавливать PHP, MySQL, Redis).
- Это первый шаг к миграции в Kubernetes: стенд уже разбит по сервисам (web/app/db/redis), остаётся только переписать в Kubernetes-манифесты.
- Ты понимаешь, как сервисы взаимодействуют друг с другом (сеть, зависимости, переменные окружения).

**Вопрос:** *круто, но хочется понять получше, зачем именно такая композиция сервисов?*  
**Ответ:**  
- Мы намеренно разделили окружение на четыре контейнера: `app` (PHP‑FPM + код), `nginx` (фронт), `db` (MySQL), `redis` (кэш/очереди). Так проще обновлять и масштабировать каждый компонент отдельно и переносить их в Kubernetes как отдельные Deployment/StatefulSet/Service.  
- Для DevOps это важно, потому что ты работаешь не с «одним большим сервером», а с набором сервисов, у каждого свои ресурсы, настройки и жизненный цикл. docker-compose даёт возможность описать это окружение как код и локально воспроизвести прод‑сценарий одной командой.

---

### Раздел 1.4: Работа с Laravel внутри контейнера (artisan через docker compose)

Команда, которую ты уже выполнял:

```bash
cd /mnt/d/DevOpsPractice/laravel-app
docker compose exec app php artisan migrate
```

**Что происходит:**

- `docker compose exec app` — запуск команды **внутри** контейнера `app` (PHP-FPM);
- `php artisan migrate` — миграции Laravel:
  - создаёт таблицы (`users`, `cache`, `jobs`, и т.д.) в базе `laravel` на сервисе `db`.

**Почему это важно DevOps’у**

- В реальных пайплайнах деплоя ты будешь:
  - запускать миграции **как отдельный шаг** (job) при деплое;
  - иногда отдельно запускать команды типа `php artisan config:cache`, `queue:restart`, `horizon`, и т.п.
- Ты уже умеешь выполнять эти команды из контейнера, а не только локально.

---

### Раздел 1.5: CI для Laravel: `.github/workflows/laravel-ci.yml`

Мы добавили отдельный workflow **«CI for Laravel App»**, который триггерится на:

```yaml
on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]
```

**Что делает job `laravel-tests-and-build`:**

1. **Поднимает MySQL как сервис GitHub Actions:**

```yaml
services:
  mysql:
    image: mysql:8.0
    env:
      MYSQL_DATABASE: laravel
      MYSQL_USER: laravel
      MYSQL_PASSWORD: secret
      MYSQL_ROOT_PASSWORD: root
```

2. **Готовит PHP-окружение:**

```yaml
uses: shivammathur/setup-php@v2
with:
  php-version: '8.3'
  extensions: mbstring, intl, pdo_mysql, xml
```

3. **Ставит зависимости и готовит Laravel:**

```yaml
working-directory: ./laravel-app/src
run: composer install --no-interaction --prefer-dist
```

```yaml
cp .env.example .env
php artisan key:generate
php artisan config:clear
```

4. **Гоняет миграции и тесты:**

```yaml
env:
  DB_CONNECTION: mysql
  DB_HOST: 127.0.0.1
  DB_PORT: 3306
  DB_DATABASE: laravel
  DB_USERNAME: laravel
  DB_PASSWORD: secret
run: php artisan migrate --force
```

```yaml
run: php artisan test
```

5. **Собирает Docker-образ для PHP-части:**

```yaml
uses: docker/build-push-action@v6
with:
  context: ./laravel-app
  file: ./laravel-app/docker/php-fpm/Dockerfile
  push: false
  tags: laravel-app-php:ci
```

**Как это использовать на собесе (технический смысл):**

- Каждый пуш/PR в `master`:
  - подтверждает, что Laravel-проект **ставится и мигрируется** на чистой машине;
  - прогоняет автоматические тесты (`php artisan test`);
  - проверяет, что Dockerfile для PHP-FPM **собирается**.
- Это полностью закрывает ожидание «**поддерживать и развивать CI/CD-процессы для Laravel-приложений**» на уровне junior/strong junior:
  - ты умеешь описать pipeline,
  - понимаешь, какие шаги важны (зависимости, миграции, тесты, сборка образа).

---

---

## Блок 2: Kubernetes

**Что мы сделали в этом блоке:**
- Развернули Laravel в Kubernetes-кластере Docker Desktop
- Создали манифесты для Deployment, Service, ConfigMap, Secret
- Развернули MySQL и Redis как отдельные сервисы
- Настроили Ingress для маршрутизации
- Выполнили миграции и диагностировали проблемы

**Закрывает требования вакансии:**
- ✅ "Развертывать и обновлять приложения в Kubernetes"
- ✅ "Понимание основ работы Kubernetes: Pods, Deployments, Services, Ingress, ConfigMaps, Secrets"
- ✅ "Обеспечивать базовую безопасность: управление секретами (Kubernetes Secrets)"
- ✅ "Опыт развертывания Laravel-приложений в Kubernetes"
- ✅ "Участвовать в инцидент-менеджменте: диагностика проблем, сбор логов"

---

### Раздел 2.1: Что такое Kubernetes и зачем он нужен

**Что мы сделали и зачем:**

Мы развернули Laravel-приложение в **Kubernetes-кластере** (Docker Desktop). Это значит, что вместо простого `docker compose up` мы теперь используем **Kubernetes-объекты** (Deployment, Service, ConfigMap, Secret), которые описывают, как приложение должно работать в продакшене.

**Почему это важно для DevOps:**

- В реальных проектах приложения почти всегда крутятся в Kubernetes (или похожих оркестраторах);
- Ты должен уметь описать приложение через YAML-манифесты и задеплоить его в кластер;
- Это закрывает требование вакансии: **"Развертывать и обновлять приложения в Kubernetes"**.

---

#### 6.1. Что такое Kubernetes и зачем он нужен

**Простыми словами:**

Kubernetes (K8s) — это **система управления контейнерами**. Представь, что у тебя есть несколько серверов (или один мощный), и ты хочешь запустить на них много разных приложений (Laravel, база данных, Redis, и т.д.).

**Без Kubernetes:**
- Ты бы вручную запускал каждый контейнер на каждом сервере;
- Если контейнер упадёт — ты должен вручную его перезапустить;
- Если нужно обновить приложение — ты останавливаешь старый контейнер и запускаешь новый (и сайт на это время недоступен).

**С Kubernetes:**
- Ты описываешь в YAML-файлах, **что** должно работать (например, "2 копии Laravel, 1 MySQL, 1 Redis");
- Kubernetes **сам** запускает контейнеры на доступных серверах;
- Если контейнер упадёт — Kubernetes **автоматически** перезапустит его;
- При обновлении Kubernetes **постепенно** заменяет старые контейнеры новыми (без простоя).

**Аналогия:**
- Без K8s = ты сам управляешь каждым контейнером вручную;
- С K8s = у тебя есть "менеджер", который следит за всеми контейнерами и делает за тебя рутинную работу.

---

### Раздел 2.2: Структура наших Kubernetes-манифестов

Мы создали папку `laravel-app/k8s/` с несколькими YAML-файлами. Каждый файл описывает **один объект Kubernetes**.

**Что мы создали:**

1. **`mysql.yaml`** — MySQL база данных
2. **`redis.yaml`** — Redis (для кеша и очередей)
3. **`configmap-env.yaml`** — переменные окружения (не секретные)
4. **`secret-env.yaml`** — секретные данные (пароли, ключи)
5. **`deployment-web.yaml`** — само Laravel-приложение (PHP-FPM + Nginx)
6. **`service-web.yaml`** — "адрес" для доступа к Laravel
7. **`ingress.yaml`** — маршрутизация HTTP-запросов
8. **`configmap-nginx.yaml`** — конфигурация Nginx

**Почему так много файлов?**

Каждый файл отвечает за **одну вещь**. Это как в программировании: лучше разбить большой код на маленькие функции, чем писать всё в одном файле. Так проще:
- Понять, что делает каждая часть;
- Изменить что-то одно, не трогая остальное;
- Переиспользовать (например, ConfigMap можно использовать в нескольких Deployment'ах).

---

### Раздел 2.3: Deployment: что это и зачем

**Файл:** `laravel-app/k8s/deployment-web.yaml`

**Что это такое:**

Deployment — это **описание того, какие контейнеры должны работать и в каком количестве**.

**Простыми словами:**

Ты говоришь Kubernetes: "Запусти мне Laravel-приложение. Внутри должно быть 2 контейнера: один с PHP-FPM (где выполняется код), другой с Nginx (который принимает HTTP-запросы). И сделай это в 1 копии (replicas: 1)".

**Что происходит, когда ты делаешь `kubectl apply -f deployment-web.yaml`:**

1. Kubernetes читает YAML-файл и понимает: "Нужно запустить Deployment с именем `laravel-web`".
2. Kubernetes создаёт **Pod** (это "коробка", в которой живут контейнеры).
3. Внутри Pod'а запускаются 2 контейнера:
   - `app` (PHP-FPM) — слушает порт 9000, выполняет Laravel-код;
   - `nginx` — слушает порт 80, принимает HTTP-запросы и проксирует их в PHP-FPM.
4. Если контейнер упадёт — Kubernetes автоматически перезапустит его.

**Почему мы используем 2 контейнера в одном Pod?**

В docker-compose у нас были отдельные сервисы `app` и `nginx`. В Kubernetes мы можем сделать так же (2 отдельных Pod'а), но для простоты мы положили оба контейнера в один Pod. Это работает, потому что:
- Контейнеры в одном Pod **делят одну сеть** (могут общаться через `localhost`);
- Nginx может проксировать запросы в PHP-FPM через `localhost:9000`;
- Это проще для учебного проекта.

**В продакшене обычно делают так:**
- Отдельный Deployment для PHP-FPM (несколько Pod'ов для масштабирования);
- Отдельный Deployment для Nginx (или используют Ingress Controller, который уже включает Nginx);
- Но для начала наш вариант (2 контейнера в одном Pod) — нормально.

**Зачем DevOps'у понимать Deployment:**

- Ты должен уметь описать приложение через Deployment;
- Понимать, как масштабировать (увеличить `replicas: 1` до `replicas: 3`);
- Знать, как обновлять (изменить `image: laravel-app-app:latest` на `image: laravel-app-app:v2` и Kubernetes постепенно обновит Pod'ы).

---

### Раздел 2.4: Service: что это и зачем

**Файл:** `laravel-app/k8s/service-web.yaml`

**Что это такое:**

Service — это **постоянный адрес для доступа к Pod'ам**. Представь, что у тебя есть 3 Pod'а с Laravel, и они постоянно перезапускаются (получают новые IP-адреса). Service даёт им **одно имя** (например, `laravel-web`), по которому можно обращаться, не зная конкретный IP.

**Простыми словами:**

- **Без Service:** "Мне нужно обратиться к Laravel, который находится по адресу `10.1.0.16`". Но если Pod перезапустится, адрес изменится на `10.1.0.20`, и всё сломается.
- **С Service:** "Мне нужно обратиться к Laravel через Service `laravel-web`". Kubernetes сам знает, какой Pod сейчас работает, и направляет запрос туда.

**Что происходит, когда ты делаешь `kubectl apply -f service-web.yaml`:**

1. Kubernetes создаёт Service с именем `laravel-web`.
2. Service получает **внутренний IP-адрес** в кластере (например, `10.105.222.45`).
3. Service **следит за Pod'ами** с label `app=laravel-web` (это мы указали в `selector`).
4. Когда Pod запускается/останавливается — Service автоматически обновляет список "живых" Pod'ов.
5. Когда кто-то обращается к `laravel-web:80`, Service **распределяет запросы** между доступными Pod'ами (если их несколько).

**Почему это нужно:**

- Другие сервисы (MySQL, Redis) могут обращаться к Laravel по имени `laravel-web`, а не по IP;
- Если Pod перезапустится — Service автоматически найдёт новый Pod;
- Можно масштабировать (запустить 5 Pod'ов), и Service будет распределять нагрузку между ними.

**Зачем DevOps'у понимать Service:**

- Ты должен уметь создать Service для своего приложения;
- Понимать разницу между типами Service (ClusterIP, NodePort, LoadBalancer);
- Знать, как проверить, что Service правильно направляет трафик (`kubectl get endpoints`).

---

### Раздел 2.5: ConfigMap и Secret: переменные окружения

**Файлы:** `configmap-env.yaml`, `secret-env.yaml`

**Что это такое:**

- **ConfigMap** — хранит **несекретные** данные (например, `APP_NAME=Laravel`, `APP_ENV=production`);
- **Secret** — хранит **секретные** данные (пароли, ключи) в закодированном виде (base64).

**Простыми словами:**

В Laravel есть файл `.env`, где хранятся настройки (база данных, Redis, ключи). В Kubernetes мы **не используем файл `.env`** напрямую, потому что:
- Файл `.env` зашит в Docker-образ, и его сложно менять без пересборки;
- В Kubernetes мы хотим **менять настройки без пересборки образа**.

Вместо этого мы:
1. Выносим настройки в **ConfigMap** (несекретные) и **Secret** (секретные);
2. В Deployment указываем, что эти переменные нужно **подставить в контейнер** как переменные окружения;
3. Laravel читает переменные окружения (они имеют приоритет над `.env` файлом).

**Что происходит, когда ты делаешь `kubectl apply -f configmap-env.yaml`:**

1. Kubernetes создаёт объект ConfigMap с именем `laravel-app-config`.
2. Внутри ConfigMap хранятся пары ключ-значение:
   ```
   APP_NAME=Laravel
   APP_ENV=production
   APP_KEY=base64:BTfPQTW53cN12TSA9kwq4u9pRRIoevOqrkPtFWndXDU=
   ```
3. В Deployment мы указываем:
   ```yaml
   envFrom:
     - configMapRef:
         name: laravel-app-config
   ```
4. Kubernetes **автоматически** подставляет все переменные из ConfigMap в контейнер как переменные окружения.

**Почему мы используем ConfigMap и Secret отдельно:**

- **ConfigMap** — для данных, которые не секретные (можно показывать в логах, в интерфейсе Kubernetes);
- **Secret** — для паролей, ключей (хранятся в base64, но это не шифрование, просто кодирование; в продакшене обычно используют внешние системы типа Vault).

**Зачем DevOps'у понимать ConfigMap/Secret:**

- Ты должен уметь вынести настройки из `.env` в ConfigMap/Secret;
- Понимать, как обновить настройки без пересборки образа (просто `kubectl apply -f configmap-env.yaml` и перезапустить Pod);
- Знать, что Secret не совсем безопасен (base64 — это не шифрование), и в проде нужно использовать более серьёзные решения.

---

### Раздел 2.6: MySQL и Redis в Kubernetes

**Файлы:** `mysql.yaml`, `redis.yaml`

**Что мы сделали:**

Мы создали отдельные Deployment'ы для MySQL и Redis, точно так же, как в docker-compose были отдельные сервисы `db` и `redis`.

**Почему это нужно:**

- Laravel должен подключаться к MySQL и Redis;
- В Kubernetes они должны быть доступны по **именам сервисов** (`mysql`, `redis`), а не по IP;
- Мы создали Service для каждого, чтобы Laravel мог обращаться к ним по имени.

**Что происходит:**

1. `kubectl apply -f mysql.yaml` создаёт:
   - Deployment с MySQL (1 Pod);
   - Service с именем `mysql` (внутренний IP, например `10.104.246.204:3306`).
2. `kubectl apply -f redis.yaml` создаёт:
   - Deployment с Redis (1 Pod);
   - Service с именем `redis` (внутренний IP, например `10.111.183.134:6379`).
3. В Laravel мы указываем:
   - `DB_HOST=mysql` (Kubernetes автоматически резолвит это имя в IP);
   - `REDIS_HOST=redis` (то же самое).

**Почему это работает:**

Kubernetes имеет **встроенный DNS**. Когда контейнер обращается к `mysql:3306`, Kubernetes:
1. Ищет Service с именем `mysql`;
2. Находит его IP (`10.104.246.204`);
3. Направляет запрос туда.

**Зачем DevOps'у понимать это:**

- Ты должен уметь развернуть базу данных и Redis в Kubernetes;
- Понимать, что сервисы общаются по **именам**, а не по IP;
- Знать, как проверить, что сервисы доступны (`kubectl get svc`, `kubectl get endpoints`).

---

### Раздел 2.7: Ingress: маршрутизация HTTP-запросов

**Файл:** `ingress.yaml`

**Что это такое:**

Ingress — это **правило, которое говорит Kubernetes, как обрабатывать HTTP-запросы извне**.

**Простыми словами:**

- Без Ingress: чтобы попасть на Laravel, нужно делать `kubectl port-forward` (это только для разработки);
- С Ingress: ты настраиваешь правило "все запросы на `laravel-app.local` направляй в Service `laravel-web`", и Kubernetes сам это обрабатывает.

**Что происходит:**

1. `kubectl apply -f ingress.yaml` создаёт Ingress-правило:
   ```yaml
   host: laravel-app.local
   backend:
     service: laravel-web
   ```
2. Если у тебя установлен **Ingress Controller** (например, Nginx Ingress Controller), он:
   - Слушает HTTP-запросы на порту 80/443;
   - Смотрит на заголовок `Host: laravel-app.local`;
   - Направляет запрос в Service `laravel-web`.

**Почему мы используем Ingress:**

- Это стандартный способ "выставить" приложение наружу в Kubernetes;
- Можно настроить несколько доменов на один кластер;
- Можно добавить SSL/TLS (HTTPS) через Ingress.

**В нашем случае (Docker Desktop):**

Ingress может не работать "из коробки", потому что нужен Ingress Controller. Поэтому мы использовали `kubectl port-forward` для доступа к приложению. Но манифест Ingress мы создали, чтобы показать, как это делается в проде.

**Зачем DevOps'у понимать Ingress:**

- Ты должен уметь создать Ingress для своего приложения;
- Понимать, как настроить несколько доменов;
- Знать, как добавить SSL-сертификаты (через cert-manager или вручную).

---

### Раздел 2.8: Команды, которые мы использовали

**`kubectl apply -f <файл.yaml>`**

**Что делает:**
- Читает YAML-файл;
- Создаёт или обновляет объект в Kubernetes (Deployment, Service, ConfigMap, и т.д.).

**Почему `apply`, а не `create`:**
- `kubectl create` — создаёт объект, но если он уже существует — выдаст ошибку;
- `kubectl apply` — создаёт, если объекта нет, или обновляет, если он уже есть (это удобнее).

**`kubectl get pods`**

**Что делает:**
- Показывает список всех Pod'ов в кластере (или в текущем namespace).

**Что смотреть:**
- `STATUS` — должен быть `Running` (если `Error` или `CrashLoopBackOff` — что-то не так);
- `READY` — например, `2/2` означает, что оба контейнера в Pod'е готовы.

**`kubectl describe pod <имя>`**

**Что делает:**
- Показывает **детальную информацию** о Pod'е: какие контейнеры, какие переменные окружения, какие события (Events).

**Зачем это нужно:**
- Если Pod не запускается — `describe` покажет, в чём проблема (образ не найден, переменные не применились, и т.д.).

**`kubectl logs <pod> -c <container>`**

**Что делает:**
- Показывает логи конкретного контейнера в Pod'е.

**Зачем это нужно:**
- Если приложение не работает — логи покажут ошибки (например, "No application encryption key has been specified").

**`kubectl exec -it <pod> -c <container> -- <команда>`**

**Что делает:**
- Выполняет команду **внутри** контейнера (как `docker exec`).

**Зачем это нужно:**
- Запустить миграции: `php artisan migrate`;
- Проверить переменные окружения: `env | grep APP_KEY`;
- Посмотреть файлы: `ls -la /var/www/html`.

**`kubectl port-forward svc/<service> <локальный_порт>:<порт_в_кластере>`**

**Что делает:**
- Пробрасывает порт с твоего компьютера в Service в кластере.

**Зачем это нужно:**
- Для доступа к приложению из браузера (например, `localhost:8083` → Service `laravel-web:80`);
- Это временное решение для разработки; в проде используют Ingress или LoadBalancer.

---

### Раздел 2.9: Проблемы, с которыми мы столкнулись, и как их решали

**Проблема 1: Nginx не мог найти PHP-FPM**

**Что было:**
- В `nginx.conf` было `fastcgi_pass app:9000` (имя сервиса из docker-compose);
- В Kubernetes контейнеры в одном Pod общаются через `localhost`, а не через имена сервисов.

**Как решили:**
- Создали ConfigMap с `nginx.conf`, где `fastcgi_pass localhost:9000`;
- Подмонтировали ConfigMap в контейнер Nginx.

**Почему это важно:**
- В Kubernetes контейнеры в одном Pod **делят сеть**, поэтому могут общаться через `localhost`;
- Контейнеры в разных Pod'ах общаются через **Service** (по имени).

**Проблема 2: Код Laravel не был в образе**

**Что было:**
- Мы использовали `emptyDir` для монтирования кода, но он был пустой;
- Laravel не мог найти файлы.

**Как решили:**
- Создали `Dockerfile.k8s`, который копирует код Laravel в образ при сборке;
- Установили зависимости через `composer install` в Dockerfile;
- Убрали `emptyDir` из deployment.

**Почему это важно:**
- В продакшене код обычно **зашит в образ** (immutable infrastructure);
- Это гарантирует, что на всех серверах один и тот же код;
- `emptyDir` используется для временных данных, а не для кода.

**Проблема 3: APP_KEY был пустой**

**Что было:**
- В ConfigMap не было `APP_KEY`;
- Laravel не мог запуститься без ключа шифрования.

**Как решили:**
- Сгенерировали ключ: `php artisan key:generate --show`;
- Добавили `APP_KEY` в ConfigMap;
- Явно указали в Deployment, что `APP_KEY` нужно брать из ConfigMap.

**Почему это важно:**
- `APP_KEY` — критически важная переменная для Laravel (шифрование сессий, cookies);
- В проде ключ должен быть в Secret, а не в ConfigMap (но для учебного проекта ConfigMap ок);
- При пересоздании Pod'а переменные из ConfigMap/Secret автоматически подтягиваются.

---

### Раздел 2.10: Итог: что мы получили

**Что работает:**
- Laravel запущен в Kubernetes (2 контейнера в одном Pod: PHP-FPM + Nginx);
- MySQL и Redis работают как отдельные сервисы;
- Laravel подключается к MySQL и Redis по именам сервисов;
- Переменные окружения управляются через ConfigMap/Secret;
- Миграции выполнены;
- Приложение доступно через `kubectl port-forward`.

**Что это даёт DevOps'у:**
- Ты умеешь описать приложение через Kubernetes-манифесты;
- Понимаешь, как работают Deployment, Service, ConfigMap, Secret;
- Знаешь, как диагностировать проблемы (`kubectl describe`, `kubectl logs`);
- Можешь обновить приложение без простоя (изменить образ в Deployment, Kubernetes постепенно обновит Pod'ы).

---

## Блок 3: Helm Chart

**Что мы сделали в этом блоке:**
- Оформили все Kubernetes-манифесты как Helm-чарт
- Создали Chart.yaml, values.yaml, templates/ с шаблонами
- Установили приложение через `helm install`
- Протестировали работу Helm-чарта

**Закрывает требования вакансии:**
- ✅ **"Развертывать и обновлять приложения в Kubernetes с использованием Helm"** — создали Helm-чарт и установили через Helm;
- ✅ **"Работать с инфраструктурой как код (IaC): писать и поддерживать конфигурации Helm-чарты"** — весь Helm-чарт описан в файлах (Chart.yaml, values.yaml, templates/).

---

### Раздел 3.1: Что такое Helm и зачем он нужен

**Что это такое:**

Helm — это **менеджер пакетов для Kubernetes** (как `apt` для Ubuntu или `npm` для Node.js, но для Kubernetes).

**Простыми словами:**

- **Без Helm:** чтобы развернуть приложение, нужно выполнить `kubectl apply -f configmap.yaml`, `kubectl apply -f secret.yaml`, `kubectl apply -f deployment.yaml` и так далее — много команд, много файлов, легко ошибиться.
- **С Helm:** одна команда `helm install laravel-app .` разворачивает всё приложение сразу, потому что Helm знает, какие файлы применять и в каком порядке.

**Почему мы заменили `kubectl apply` на `helm install`:**

1. **Удобство:** вместо 8 команд (`kubectl apply -f ...`) — одна команда (`helm install`).
2. **Параметризация:** можно менять настройки (количество реплик, образы, пароли) через `values.yaml`, не редактируя манифесты.
3. **Версионирование:** Helm хранит историю установок (revisions), можно откатиться назад.
4. **Шаблонизация:** манифесты становятся шаблонами, можно использовать переменные (например, `{{ .Values.app.replicas }}`).

**Зачем DevOps'у понимать это:**

- В вакансии прямо указано: **"Развертывать и обновлять приложения в Kubernetes с использованием Helm"**;
- Helm — стандарт де-факто для управления приложениями в Kubernetes;
- Большинство приложений в продакшене разворачиваются через Helm, а не через `kubectl apply`.

---

### Раздел 3.2: Структура Helm-чарта

**Что мы создали:**

```
laravel-app/helm/laravel-app/
├── Chart.yaml          # Метаданные чарта (название, версия)
├── values.yaml         # Дефолтные значения (переменные)
├── templates/          # Шаблоны Kubernetes-манифестов
│   ├── _helpers.tpl    # Вспомогательные функции
│   ├── configmap-env.yaml
│   ├── configmap-nginx.yaml
│   ├── secret-env.yaml
│   ├── deployment-web.yaml
│   ├── service-web.yaml
│   ├── ingress.yaml
│   ├── mysql.yaml
│   └── redis.yaml
└── README.md           # Документация
```

**Простыми словами:**

- **Chart.yaml** — это "паспорт" чарта: название, версия, описание. Kubernetes не использует этот файл напрямую, но Helm читает его, чтобы понять, что это за чарт.
- **values.yaml** — это "настройки по умолчанию": все переменные, которые можно менять (количество реплик, образы, пароли, имена сервисов).
- **templates/** — это "шаблоны манифестов": те же самые YAML-файлы, что были в `k8s/`, но с переменными вместо жёстко заданных значений.

**Пример:**

**Было (в `k8s/deployment-web.yaml`):**
```yaml
spec:
  replicas: 1  # Жёстко задано: 1 реплика
```

**Стало (в `helm/laravel-app/templates/deployment-web.yaml`):**
```yaml
spec:
  replicas: {{ .Values.app.replicas }}  # Переменная из values.yaml
```

Теперь можно изменить количество реплик, не редактируя манифест:
```yaml
# values.yaml
app:
  replicas: 3  # Меняем здесь
```

---

### Раздел 3.3: Chart.yaml и values.yaml

**Chart.yaml:**

```yaml
apiVersion: v2
name: laravel-app
description: A Helm chart for Laravel application
type: application
version: 0.1.0
appVersion: "1.0.0"
```

**Что это значит:**

- `name` — имя чарта (используется в командах `helm install laravel-app .`);
- `version` — версия самого чарта (когда меняешь структуру чарта, увеличиваешь версию);
- `appVersion` — версия приложения, которое разворачивает чарт (версия Laravel-приложения).

**values.yaml:**

```yaml
app:
  name: laravel-app
  image:
    app: laravel-app-app:latest
    nginx: laravel-app-nginx:latest
  replicas: 1

laravel:
  appName: "Laravel"
  appEnv: "production"
  appDebug: "false"
  appUrl: "http://laravel-app.local"
  appKey: "base64:BTfPQTW53cN12TSA9kwq4u9pRRIoevOqrkPtFWndXDU="

mysql:
  enabled: true
  image: mysql:8.0
  database: laravel
  username: laravel_user
  password: laravel_password
```

**Что это значит:**

- Все эти значения можно менять, не трогая шаблоны;
- В шаблонах они используются как `{{ .Values.mysql.database }}`, `{{ .Values.app.replicas }}` и т.д.;
- Можно переопределить через `-f my-values.yaml` или `--set app.replicas=3`.

**Зачем DevOps'у понимать это:**

- Ты должен уметь настраивать приложение через `values.yaml`, не редактируя шаблоны;
- Понимать, что `values.yaml` — это "точка входа" для настройки приложения;
- Знать, как переопределить значения при установке (`helm install ... --set key=value`).

---

### Раздел 3.4: Шаблоны (templates/)

**Что мы сделали:**

Преобразовали все манифесты из `k8s/` в шаблоны в `templates/`, заменив жёстко заданные значения на переменные.

**Примеры изменений:**

**1. Имена ресурсов:**

**Было:**
```yaml
metadata:
  name: laravel-web
```

**Стало:**
```yaml
metadata:
  name: {{ include "laravel-app.fullname" . }}-web
```

Теперь имя формируется автоматически: `laravel-app-web` (если релиз называется `laravel-app`).

**2. Количество реплик:**

**Было:**
```yaml
spec:
  replicas: 1
```

**Стало:**
```yaml
spec:
  replicas: {{ .Values.app.replicas }}
```

Теперь можно менять через `values.yaml` или `--set app.replicas=3`.

**3. Условная установка:**

**Было:** MySQL и Redis всегда разворачивались.

**Стало:**
```yaml
{{- if .Values.mysql.enabled -}}
apiVersion: apps/v1
kind: Deployment
...
{{- end }}
```

Теперь можно отключить MySQL, установив `mysql.enabled: false` в `values.yaml`.

**4. Кодирование паролей:**

**Было:**
```yaml
data:
  DB_PASSWORD: c2VjcmV0  # Жёстко задано в base64
```

**Стало:**
```yaml
data:
  DB_PASSWORD: {{ .Values.mysql.password | b64enc | quote }}
```

Теперь пароль берётся из `values.yaml` и автоматически кодируется в base64.

**Зачем DevOps'у понимать это:**

- Ты должен уметь читать и модифицировать Helm-шаблоны;
- Понимать синтаксис шаблонов (`{{ .Values... }}`, `{{- if ... -}}`);
- Знать, как использовать функции Helm (`b64enc`, `quote`, `include`).

---

### Раздел 3.5: Установка и использование Helm-чарта

**Команды, которые мы использовали:**

**1. Проверка шаблонов (dry-run):**
```bash
helm template laravel-app . --debug
```

**Что это делает:**
- Генерирует финальные YAML-манифесты из шаблонов, но не применяет их;
- Показывает, что получится после подстановки переменных;
- `--debug` показывает все шаблоны и значения.

**Зачем это нужно:**
- Проверить, что шаблоны правильные, до установки;
- Увидеть финальные значения переменных;
- Отладить ошибки в шаблонах.

**2. Установка:**
```bash
helm install laravel-app .
```

**Что это делает:**
- Читает `Chart.yaml` и `values.yaml`;
- Генерирует манифесты из шаблонов в `templates/`;
- Применяет их через `kubectl apply`;
- Создаёт Helm-релиз (запись о том, что установлено).

**3. Проверка статуса:**
```bash
helm status laravel-app
```

**Что это показывает:**
- Имя релиза, дату установки, статус (deployed);
- Ревизию (revision) — номер версии установки;
- Список ресурсов, которые были созданы.

**4. Обновление:**
```bash
helm upgrade laravel-app . --set app.replicas=3
```

**Что это делает:**
- Обновляет существующий релиз с новыми значениями;
- `--set app.replicas=3` переопределяет значение из `values.yaml`;
- Helm создаёт новую ревизию (revision 2, 3 и т.д.).

**5. Удаление:**
```bash
helm uninstall laravel-app
```

**Что это делает:**
- Удаляет все ресурсы, созданные при установке;
- Удаляет запись о релизе из Helm.

**Зачем DevOps'у понимать это:**

- Ты должен уметь устанавливать, обновлять и удалять приложения через Helm;
- Понимать, что Helm хранит историю (revisions), можно откатиться назад;
- Знать, как переопределить значения при установке/обновлении.

---

### Раздел 3.6: Сравнение: kubectl apply vs helm install

**Было (через kubectl):**

```bash
# Нужно применять каждый файл отдельно
kubectl apply -f k8s/configmap-env.yaml
kubectl apply -f k8s/secret-env.yaml
kubectl apply -f k8s/configmap-nginx.yaml
kubectl apply -f k8s/mysql.yaml
kubectl apply -f k8s/redis.yaml
kubectl apply -f k8s/deployment-web.yaml
kubectl apply -f k8s/service-web.yaml
kubectl apply -f k8s/ingress.yaml

# Итого: 8 команд
```

**Проблемы:**
- Много команд, легко забыть какой-то файл;
- Нет версионирования (не знаешь, что было установлено);
- Чтобы изменить настройки, нужно редактировать файлы;
- Нет возможности откатиться назад.

**Стало (через Helm):**

```bash
# Одна команда
helm install laravel-app helm/laravel-app/

# Или с кастомными значениями
helm install laravel-app helm/laravel-app/ --set app.replicas=3
```

**Преимущества:**
- Одна команда вместо восьми;
- Версионирование (Helm хранит историю);
- Легко менять настройки через `values.yaml` или `--set`;
- Можно откатиться назад (`helm rollback laravel-app 1`).

**Зачем DevOps'у понимать это:**

- В вакансии указано: **"Развертывать и обновлять приложения в Kubernetes с использованием Helm"**;
- Helm — стандарт для продакшена, `kubectl apply` используется только для простых случаев;
- Понимать, когда использовать Helm (сложные приложения), а когда `kubectl apply` (простые тесты).

---

### Раздел 3.7: Итог: что мы получили

**Что мы сделали:**

1. Создали структуру Helm-чарта (`Chart.yaml`, `values.yaml`, `templates/`);
2. Преобразовали все манифесты в шаблоны с переменными;
3. Установили приложение через `helm install`;
4. Протестировали работу (миграции, доступность).

**Что мы получили:**

- **Удобство:** одна команда вместо восьми;
- **Гибкость:** можно менять настройки через `values.yaml`;
- **Версионирование:** Helm хранит историю установок;
- **Стандартизация:** структура чарта соответствует best practices.

**Привязка к вакансии:**

- ✅ **"Развертывать и обновлять приложения в Kubernetes с использованием Helm"** — создали Helm-чарт и установили через Helm;
- ✅ **"Работать с инфраструктурой как код (IaC): писать и поддерживать конфигурации Helm-чарты"** — весь чарт описан в файлах, можно версионировать в Git;
- ✅ **"Опыт использования инструментов IaC (Terraform, Helm — хотя бы на уровне учебных проектов)"** — создали и использовали Helm-чарт на практике.

**Вопросы для самопроверки:**

1. **Что такое Helm?** — Менеджер пакетов для Kubernetes, позволяет разворачивать приложения одной командой.
2. **Зачем нужен Helm, если есть kubectl?** — Удобство (одна команда), версионирование, возможность менять настройки без редактирования манифестов.
3. **Что такое values.yaml?** — Файл с настройками по умолчанию, которые можно переопределить при установке.
4. **Что такое templates/?** — Папка с шаблонами Kubernetes-манифестов, где жёстко заданные значения заменены на переменные.
5. **Как установить приложение через Helm?** — `helm install <name> <path>`.
6. **Как обновить приложение?** — `helm upgrade <name> <path> --set key=value`.
7. **Как откатиться назад?** — `helm rollback <name> <revision>`.

---

---

## Блок 4: Мониторинг (Prometheus + Grafana)

**Что мы сделали в этом блоке:**
- Установили kube-prometheus-stack через Helm
- Получили доступ к Grafana (веб-интерфейс для графиков)
- Изучили готовые дашборды для мониторинга Kubernetes
- Поняли, как отслеживать метрики кластера и приложений

**Закрывает требования вакансии:**
- ✅ **"Настраивать и поддерживать мониторинг, логирование и алертинг (например, Prometheus + Grafana)"** — установили Prometheus и Grafana, настроили доступ;
- ✅ **"Опыт работы с системами мониторинга (Prometheus, Grafana и др.)"** — работали с Grafana-дашбордами, понимаем структуру метрик.

---

### Раздел 4.1: Что такое мониторинг и зачем он нужен

**Что это такое:**

Мониторинг — это **отслеживание состояния системы в реальном времени**: сколько ресурсов (CPU, память, сеть) использует приложение, работает ли оно, есть ли ошибки.

**Простыми словами:**

- **Без мониторинга:** ты не знаешь, что происходит с приложением. Оно упало? Перегружено? Есть ошибки? Узнаёшь только когда пользователи жалуются.
- **С мониторингом:** ты видишь графики в реальном времени: "CPU подскочил до 90%", "Память растёт", "Количество ошибок увеличилось". Можешь предотвратить проблемы до того, как они станут критическими.

**Почему это важно для DevOps:**

- **Проактивность:** видишь проблемы до того, как они влияют на пользователей;
- **Диагностика:** когда что-то сломалось, можешь посмотреть метрики и понять причину;
- **Планирование:** видишь, сколько ресурсов нужно приложению, можешь правильно настроить лимиты в Kubernetes.

**Зачем DevOps'у понимать это:**

- В вакансии прямо указано: **"Настраивать и поддерживать мониторинг, логирование и алертинг (например, Prometheus + Grafana)"**;
- Мониторинг — обязательная часть продакшена, без него нельзя запускать приложения;
- DevOps должен уметь настроить мониторинг и интерпретировать метрики.

---

### Раздел 4.2: Prometheus: сбор метрик

**Что это такое:**

Prometheus — это **система сбора и хранения метрик**. Она периодически опрашивает (scrape) сервисы и собирает данные о CPU, памяти, сети, количестве запросов и т.д.

**Простыми словами:**

- Prometheus — это "сборщик данных". Он каждые 15 секунд (по умолчанию) спрашивает у подов: "Сколько CPU используешь? Сколько памяти? Сколько запросов обработал?"
- Все эти данные сохраняются в базу данных временных рядов (time-series database).
- Потом Grafana читает эти данные и показывает красивые графики.

**Что мы установили:**

```bash
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring --create-namespace
```

**Что это установило:**

1. **Prometheus** — сам сборщик метрик;
2. **Grafana** — веб-интерфейс для визуализации;
3. **Alertmanager** — система уведомлений (если что-то пошло не так);
4. **kube-state-metrics** — метрики о состоянии Kubernetes-ресурсов (поды, деплойменты и т.д.);
5. **node-exporter** — метрики узлов кластера (CPU, память, диск).

**Зачем DevOps'у понимать это:**

- Ты должен знать, что Prometheus собирает метрики автоматически;
- Понимать, что метрики хранятся во временных рядах (можно посмотреть историю);
- Знать, что Prometheus опрашивает сервисы по HTTP endpoint `/metrics`.

---

### Раздел 4.3: Grafana: визуализация метрик

**Что это такое:**

Grafana — это **веб-интерфейс для создания графиков и дашбордов** на основе данных из Prometheus (и других источников).

**Простыми словами:**

- Prometheus хранит данные, но это просто числа. Grafana берёт эти числа и рисует красивые графики, таблицы, дашборды.
- Ты открываешь Grafana в браузере, видишь графики CPU, памяти, сети в реальном времени.

**Как мы получили доступ:**

1. **Получили пароль:**
   ```bash
   kubectl get secret prometheus-grafana -n monitoring \
     -o jsonpath="{.data.admin-password}" | base64 -d
   ```

2. **Настроили port-forward:**
   ```bash
   kubectl port-forward -n monitoring service/prometheus-grafana 3000:80
   ```

3. **Открыли в браузере:** `http://localhost:3000`
   - Username: `admin`
   - Password: (полученный из Secret)

**Что мы увидели:**

- **Готовые дашборды:**
  - "Kubernetes / Compute Resources / Cluster" — метрики всего кластера;
  - "Kubernetes / Compute Resources / Namespace" — метрики по namespace;
  - "Kubernetes / Compute Resources / Pod" — метрики конкретных подов.

- **Метрики:**
  - CPU Usage (использование процессора);
  - Memory Usage (использование памяти);
  - CPU/Memory Requests Commitment (сколько ресурсов запрошено);
  - Network Usage (сетевой трафик).

**Зачем DevOps'у понимать это:**

- Ты должен уметь получить доступ к Grafana (через port-forward или Ingress);
- Знать, где искать метрики (готовые дашборды или создать свои);
- Понимать, что означают метрики (CPU, память, сеть).

---

### Раздел 4.4: Какие метрики важны для Laravel-приложения

**Что мы можем отслеживать:**

1. **Метрики кластера:**
   - CPU Usage — сколько процессора использует весь кластер;
   - Memory Usage — сколько памяти использует кластер;
   - Network Traffic — сетевой трафик.

2. **Метрики namespace (default):**
   - Сколько ресурсов использует твоё Laravel-приложение (все поды вместе);
   - Сравнение с другими namespace (monitoring, kube-system).

3. **Метрики конкретных подов:**
   - `laravel-app-web` — CPU и память веб-сервера (PHP-FPM + Nginx);
   - `laravel-app-mysql` — CPU и память базы данных;
   - `laravel-app-redis` — CPU и память Redis.

**Почему это важно:**

- **Выявление проблем:** если CPU подскочил до 90%, значит приложение перегружено;
- **Планирование ресурсов:** видишь, сколько ресурсов нужно, можешь правильно настроить `requests` и `limits` в Kubernetes;
- **Масштабирование:** если CPU постоянно высокий, нужно увеличить количество реплик (`replicas: 3`).

**Зачем DevOps'у понимать это:**

- Ты должен уметь интерпретировать метрики (высокий CPU = проблема);
- Знать, какие метрики важны для веб-приложений (CPU, память, сеть);
- Понимать, как метрики связаны с настройками Kubernetes (requests, limits, replicas).

---

### Раздел 4.5: Почему "No data" в Docker Desktop

**Что мы видели:**

В некоторых дашбордах Grafana показывалось "No data" вместо графиков.

**Почему это происходит:**

1. **node-exporter в CrashLoopBackOff:**
   - node-exporter собирает метрики узлов (CPU, память, диск на уровне виртуальной машины);
   - В Docker Desktop он может не работать из-за ограничений WSL2;
   - Это не критично для базового мониторинга.

2. **Ограничения Docker Desktop:**
   - Docker Desktop использует виртуальную машину, не все метрики доступны;
   - В реальном кластере (например, на серверах) метрики будут работать полностью.

**Что всё равно работает:**

- Метрики подов (CPU, память контейнеров) — собираются через kubelet;
- Метрики Kubernetes-ресурсов (поды, деплойменты) — собираются через kube-state-metrics;
- Метрики приложений — если приложение экспортирует метрики в Prometheus-формате.

**Зачем DevOps'у понимать это:**

- Ты должен знать, что в локальной разработке (Docker Desktop) не все метрики доступны;
- Понимать разницу между локальной средой и продакшеном;
- Знать, что в реальном кластере метрики будут работать полностью.

---

### Раздел 4.6: Итог: что мы получили

**Что мы сделали:**

1. Установили kube-prometheus-stack через Helm (Prometheus + Grafana + Alertmanager);
2. Получили доступ к Grafana через port-forward;
3. Изучили готовые дашборды для мониторинга Kubernetes;
4. Поняли структуру метрик (CPU, память, сеть).

**Что мы получили:**

- **Визуализация метрик:** видим графики CPU, памяти, сети в реальном времени;
- **Готовые дашборды:** не нужно создавать с нуля, всё уже есть;
- **Мониторинг кластера:** видим состояние всего Kubernetes-кластера;
- **Мониторинг приложений:** можем отслеживать метрики конкретных подов.

**Привязка к вакансии:**

- ✅ **"Настраивать и поддерживать мониторинг, логирование и алертинг (например, Prometheus + Grafana)"** — установили Prometheus и Grafana, настроили доступ, изучили дашборды;
- ✅ **"Опыт работы с системами мониторинга (Prometheus, Grafana и др.)"** — работали с Grafana-дашбордами, понимаем структуру метрик и их интерпретацию.

**Вопросы для самопроверки:**

1. **Что такое Prometheus?** — Система сбора и хранения метрик, опрашивает сервисы и собирает данные о CPU, памяти, сети.
2. **Что такое Grafana?** — Веб-интерфейс для визуализации метрик, создаёт графики и дашборды на основе данных из Prometheus.
3. **Зачем нужен мониторинг?** — Чтобы видеть состояние системы в реальном времени, выявлять проблемы до того, как они станут критическими, планировать ресурсы.
4. **Как получить доступ к Grafana?** — Через `kubectl port-forward` или Ingress, затем открыть в браузере.
5. **Какие метрики важны для веб-приложений?** — CPU Usage, Memory Usage, Network Traffic.
6. **Почему в Docker Desktop может быть "No data"?** — node-exporter может не работать из-за ограничений WSL2, но метрики подов всё равно собираются.

---

---

## Блок 5: Health Checks и NetworkPolicy

**Что мы сделали в этом блоке:**
- Настроили health checks (liveness/readiness probes) для Laravel-приложения
- Увеличили количество реплик до 2 для отказоустойчивости и распределения нагрузки
- Создали NetworkPolicy для базовой безопасности сетей в Kubernetes

**Закрывает требования вакансии:**
- ✅ **"Взаимодействовать с командой бэкенд-разработчиков: помогать с оптимизацией окружения, настройкой health-чеков"** — настроили liveness и readiness probes;
- ✅ **"Обеспечивать базовую безопасность: настройка NetworkPolicy"** — создали NetworkPolicy для ограничения сетевого трафика;
- ✅ **"Понимание основ безопасности и сетей в Kubernetes"** — понимаем, как работают health checks и NetworkPolicy.

---

### Раздел 5.1: Health Checks (liveness/readiness probes)

**Что это такое:**

Health checks — это **проверки, которые Kubernetes выполняет, чтобы убедиться, что приложение работает и готово принимать трафик**.

**Простыми словами:**

- **Liveness probe** — проверяет, что приложение живое (если не отвечает — Kubernetes перезапускает под);
- **Readiness probe** — проверяет, что приложение готово принимать трафик (если не готово — Kubernetes убирает под из Service, трафик не идёт).

**Что мы настроили:**

```yaml
livenessProbe:
  tcpSocket:
    port: 9000
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  tcpSocket:
    port: 9000
  initialDelaySeconds: 10
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3
```

**Что это значит:**

- `tcpSocket: port: 9000` — проверяет, что порт 9000 (PHP-FPM) открыт и доступен;
- `initialDelaySeconds: 30` — ждёт 30 секунд перед первой проверкой (даёт время приложению запуститься);
- `periodSeconds: 10` — проверяет каждые 10 секунд;
- `failureThreshold: 3` — если 3 проверки подряд не прошли, считается, что приложение не работает.

**Почему мы использовали `tcpSocket`, а не `exec`:**

Изначально пробовали `exec` с командой `pgrep php-fpm`, но получили ошибку:
```
exec: "pgrep": executable file not found in $PATH
```

`pgrep` отсутствует в образе PHP-FPM. Использовали `tcpSocket`, который проверяет доступность порта 9000 (PHP-FPM слушает на этом порту).

**Что это даёт:**

- **Автоматический перезапуск:** если PHP-FPM упадёт, Kubernetes автоматически перезапустит под (liveness probe);
- **Защита от ошибок:** если приложение не готово, трафик не идёт на него (readiness probe), пользователи не получат 500 ошибок;
- **Rolling updates:** при обновлении Kubernetes ждёт, пока новый под пройдёт readiness probe, прежде чем удалить старый.

**Зачем DevOps'у понимать это:**

- В вакансии указано: **"Взаимодействовать с командой бэкенд-разработчиков: помогать с оптимизацией окружения, настройкой health-чеков"**;
- Health checks — обязательная часть продакшена, без них приложение может работать некорректно;
- Ты должен уметь настраивать probes и понимать разницу между liveness и readiness.

---

### Раздел 5.2: Отказоустойчивость через реплики

**Что мы сделали:**

Увеличили количество реплик с 1 до 2:
```bash
helm upgrade laravel-app helm/laravel-app/ --set app.replicas=2
```

**Что это даёт:**

1. **Отказоустойчивость:** если один под упадёт, второй продолжит работать;
2. **Распределение нагрузки:** Service автоматически распределяет трафик между подами (load balancing);
3. **Rolling updates:** при обновлении Kubernetes создаёт новый под, ждёт пока он станет ready, затем удаляет старый (без простоя).

**Как это работает:**

- Service `laravel-app-web` знает оба пода через labels;
- Когда приходит запрос, Service выбирает один из подов (round-robin);
- Если один под не готов (readiness probe failed), трафик идёт только на второй.

**Проверка:**

```bash
kubectl get endpoints laravel-app-web
# Вывод: 10.1.0.51:80,10.1.0.52:80 (два IP-адреса)
```

**Зачем DevOps'у понимать это:**

- Ты должен понимать, что `replicas: 2` даёт отказоустойчивость;
- Знать, как Service распределяет трафик между подами;
- Понимать, что больше реплик = больше отказоустойчивость, но больше потребление ресурсов.

---

### Раздел 5.3: NetworkPolicy (базовая безопасность)

**Что это такое:**

NetworkPolicy — это **правило, которое ограничивает сетевой трафик между подами в Kubernetes**. Ты указываешь, какие поды могут общаться друг с другом и через какие порты.

**Простыми словами:**

- **Без NetworkPolicy:** все поды могут общаться друг с другом (потенциальная уязвимость);
- **С NetworkPolicy:** только разрешённые соединения (например, Laravel → MySQL, Laravel → Redis).

**Что мы создали:**

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: laravel-app-network-policy
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: laravel-app
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
        - namespaceSelector: {}
  egress:
    - to:
        - podSelector:
            matchLabels:
              app: laravel-app-mysql
      ports:
        - protocol: TCP
          port: 3306
    - to:
        - podSelector:
            matchLabels:
              app: laravel-app-redis
      ports:
        - protocol: TCP
          port: 6379
    - to:
        - namespaceSelector:
            matchLabels:
              name: kube-system
      ports:
        - protocol: UDP
          port: 53
    - {}
```

**Что это значит:**

- `podSelector` — применяется к подам с лейблом `app.kubernetes.io/name: laravel-app` (твои Laravel-поды);
- `ingress` — разрешает входящий трафик из любого namespace (`namespaceSelector: {}`);
- `egress` — разрешает исходящий трафик:
  - К MySQL (порт 3306);
  - К Redis (порт 6379);
  - DNS в kube-system (порт 53 UDP) — обязательно для работы Kubernetes;
  - Последнее правило `- {}` разрешает весь остальной трафик (интернет, composer и т.д.).

**Почему мы создали шаблон в Helm:**

Изначально создали файл `k8s/networkpolicy.yaml` для применения через `kubectl apply`, но затем перенесли в Helm-чарт (`helm/laravel-app/templates/networkpolicy.yaml`), чтобы всё управлялось через Helm.

**Что это даёт:**

- **Безопасность:** Laravel-поды могут общаться только с MySQL и Redis, а не со всеми подами в кластере;
- **Защита от атак:** если злоумышленник получит доступ к одному поду, он не сможет подключиться к другим подам (кроме разрешённых);
- **Соответствие best practices:** NetworkPolicy — стандартная практика для продакшена.

**Зачем DevOps'у понимать это:**

- В вакансии указано: **"Обеспечивать базовую безопасность: настройка NetworkPolicy"**;
- NetworkPolicy — важная часть безопасности в Kubernetes;
- Ты должен уметь создавать NetworkPolicy и понимать, как они ограничивают трафик.

---

### Раздел 5.4: Итог: что мы получили

**Что мы сделали:**

1. Настроили health checks (liveness/readiness probes) через `tcpSocket` на порту 9000;
2. Увеличили количество реплик до 2 для отказоустойчивости и распределения нагрузки;
3. Создали NetworkPolicy в Helm-чарте для базовой безопасности сетей.

**Что мы получили:**

- **Автоматический перезапуск:** если приложение упадёт, Kubernetes автоматически перезапустит под;
- **Защита от ошибок:** если приложение не готово, трафик не идёт на него;
- **Отказоустойчивость:** если один под упадёт, второй продолжит работать;
- **Распределение нагрузки:** Service автоматически распределяет трафик между подами;
- **Безопасность:** NetworkPolicy ограничивает сетевой трафик между подами.

**Привязка к вакансии:**

- ✅ **"Взаимодействовать с командой бэкенд-разработчиков: помогать с оптимизацией окружения, настройкой health-чеков"** — настроили liveness и readiness probes;
- ✅ **"Обеспечивать базовую безопасность: настройка NetworkPolicy"** — создали NetworkPolicy для ограничения сетевого трафика;
- ✅ **"Понимание основ безопасности и сетей в Kubernetes"** — понимаем, как работают health checks и NetworkPolicy.

**Вопросы для самопроверки:**

1. **Что такое liveness probe?** — Проверка, что приложение живое (если не отвечает — Kubernetes перезапускает под).
2. **Что такое readiness probe?** — Проверка, что приложение готово принимать трафик (если не готово — трафик не идёт на него).
3. **Почему мы использовали `tcpSocket`, а не `exec`?** — `pgrep` отсутствует в образе PHP-FPM, поэтому используем проверку порта.
4. **Зачем нужны реплики?** — Для отказоустойчивости (если один под упадёт, второй продолжит работать) и распределения нагрузки.
5. **Что такое NetworkPolicy?** — Правило, которое ограничивает сетевой трафик между подами в Kubernetes.
6. **Зачем нужен NetworkPolicy?** — Для безопасности: ограничивает, какие поды могут общаться друг с другом и через какие порты.

---


